{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from w2v_utils import *\n",
    "\n",
    "words, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Cosine similarity reflects the degree of similariy between u and v\n",
    "        \n",
    "    Arguments:\n",
    "        u -- a word vector of shape (n,)          \n",
    "        v -- a word vector of shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n",
    "    \"\"\"\n",
    "\n",
    "    uu = np.sqrt(np.sum(np.square(u)))\n",
    "    vv = np.sqrt(np.sum(np.square(v)))\n",
    "    dot = np.sum(np.multiply(u, v))\n",
    "    cos = dot / (uu * vv)\n",
    "    return cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.8909038442893616\n",
      "cosine_similarity(ball, crocodile) =  0.2743924626137942\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.6751479308174201\n"
     ]
    }
   ],
   "source": [
    "father = word_to_vec_map[\"father\"]\n",
    "mother = word_to_vec_map[\"mother\"]\n",
    "ball = word_to_vec_map[\"ball\"]\n",
    "crocodile = word_to_vec_map[\"crocodile\"]\n",
    "france = word_to_vec_map[\"france\"]\n",
    "italy = word_to_vec_map[\"italy\"]\n",
    "paris = word_to_vec_map[\"paris\"]\n",
    "rome = word_to_vec_map[\"rome\"]\n",
    "\n",
    "print(\"cosine_similarity(father, mother) = \", cosine_similarity(father, mother))\n",
    "print(\"cosine_similarity(ball, crocodile) = \",cosine_similarity(ball, crocodile))\n",
    "print(\"cosine_similarity(france - paris, rome - italy) = \",cosine_similarity(france - paris, rome - italy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Performs the word analogy task as explained above: a is to b as c is to ____.\n",
    "\n",
    "    Arguments:\n",
    "    word_a -- a word, string\n",
    "    word_b -- a word, string\n",
    "    word_c -- a word, string\n",
    "    word_to_vec_map -- dictionary that maps words to their corresponding vectors.\n",
    "\n",
    "    Returns:\n",
    "    best_word --  the word such that v_b - v_a is close to v_best_word - v_c, as measured by cosine similarity\n",
    "    \"\"\"\n",
    "    # convert words to lower case\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "    word_d = word_c\n",
    "\n",
    "    e_a = word_to_vec_map[word_a]\n",
    "    e_b = word_to_vec_map[word_b]\n",
    "    e_c = word_to_vec_map[word_c]\n",
    "    e_d = e_c\n",
    "    cos_d = -1\n",
    "\n",
    "    for w_x, e_x in word_to_vec_map.items():\n",
    "        if w_x == word_a or w_x == word_b or w_x == word_c:\n",
    "            continue\n",
    "        \n",
    "        cos_x = cosine_similarity(e_a - e_b, e_c - e_x)\n",
    "        if cos_x > cos_d:\n",
    "            cos_d = cos_x\n",
    "            word_d = w_x\n",
    "            e_d = e_x\n",
    "\n",
    "    return word_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: spain -> spanish\n",
      "india -> delhi :: japan -> tokyo\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [('italy', 'italian', 'spain'), ('india', 'delhi', 'japan'), ('man', 'woman', 'boy'), ('small', 'smaller', 'large')]\n",
    "for triad in triads_to_try:\n",
    "    print ('{} -> {} :: {} -> {}'.format( *triad, complete_analogy(*triad,word_to_vec_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father -> doctor :: mother -> patient\n",
      "man -> programmer :: woman -> märklin\n"
     ]
    }
   ],
   "source": [
    "# 我自己来试试詷偏差\n",
    "triads_to_try = [('father', 'doctor', 'mother'), ('man', 'programmer', 'woman')]\n",
    "for triad in triads_to_try:\n",
    "    print ('{} -> {} :: {} -> {}'.format( *triad, complete_analogy(*triad,word_to_vec_map)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Debiasing word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.087144    0.2182     -0.40986    -0.03922    -0.1032      0.94165\n",
      " -0.06042     0.32988     0.46144    -0.35962     0.31102    -0.86824\n",
      "  0.96006     0.01073     0.24337     0.08193    -1.02722    -0.21122\n",
      "  0.695044   -0.00222     0.29106     0.5053     -0.099454    0.40445\n",
      "  0.30181     0.1355     -0.0606     -0.07131    -0.19245    -0.06115\n",
      " -0.3204      0.07165    -0.13337    -0.25068714 -0.14293    -0.224957\n",
      " -0.149       0.048882    0.12191    -0.27362    -0.165476   -0.20426\n",
      "  0.54376    -0.271425   -0.10245    -0.32108     0.2516     -0.33455\n",
      " -0.04371     0.01258   ]\n",
      "List of names and their similarities with constructed vector:\n",
      "john -0.23163356145973724\n",
      "marie 0.31559793539607295\n",
      "sophie 0.31868789859418784\n",
      "ronaldo -0.31244796850329437\n",
      "priya 0.17632041839009405\n",
      "rahul -0.16915471039231722\n",
      "danielle 0.24393299216283895\n",
      "reza -0.07930429672199553\n",
      "katy 0.2831068659572615\n",
      "yasmin 0.23313857767928758\n",
      "Other words and their similarities:\n",
      "lipstick 0.2769191625638267\n",
      "guns -0.1888485567898898\n",
      "science -0.060829065409296994\n",
      "arts 0.008189312385880347\n",
      "literature 0.06472504433459929\n",
      "warrior -0.20920164641125288\n",
      "doctor 0.11895289410935038\n",
      "tree -0.0708939917547809\n",
      "receptionist 0.3307794175059375\n",
      "technology -0.13193732447554293\n",
      "fashion 0.03563894625772699\n",
      "teacher 0.1792092343182567\n",
      "engineer -0.0803928049452407\n",
      "pilot 0.001076449899191721\n",
      "computer -0.10330358873850495\n",
      "singer 0.1850051813649629\n"
     ]
    }
   ],
   "source": [
    "g = word_to_vec_map['woman'] - word_to_vec_map['man']\n",
    "print(g)\n",
    "\n",
    "\n",
    "print ('List of names and their similarities with constructed vector:')\n",
    "# girls and boys name\n",
    "name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n",
    "for w in name_list:\n",
    "    print (w, cosine_similarity(word_to_vec_map[w], g))\n",
    "\n",
    "\n",
    "print('Other words and their similarities:')\n",
    "word_list = ['lipstick', 'guns', 'science', 'arts', 'literature', 'warrior','doctor', 'tree', 'receptionist', \n",
    "             'technology',  'fashion', 'teacher', 'engineer', 'pilot', 'computer', 'singer']\n",
    "for w in word_list:\n",
    "    print (w, cosine_similarity(word_to_vec_map[w], g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize(word, g, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Removes the bias of \"word\" by projecting it on the space orthogonal to the bias axis.\n",
    "    This function ensures that gender neutral words are zero in the gender subspace.\n",
    "\n",
    "    Arguments:\n",
    "        word -- string indicating the word to debias\n",
    "        g -- numpy-array of shape (50,), corresponding to the bias axis (such as gender)\n",
    "        word_to_vec_map -- dictionary mapping words to their corresponding vectors.\n",
    "\n",
    "    Returns:\n",
    "        e_debiased -- neutralized word vector representation of the input \"word\"\n",
    "    \"\"\"\n",
    "    e = word_to_vec_map[word]\n",
    "    e_biascomponent = np.dot(e, g) / np.sum(np.square(g)) * g\n",
    "    return e - e_biascomponent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity between receptionist and g, before neutralizing:  0.3307794175059375\n",
      "cosine similarity between receptionist and g, after neutralizing:  -5.603740393746121e-17\n"
     ]
    }
   ],
   "source": [
    "e = \"receptionist\"\n",
    "print(\"cosine similarity between \" + e + \" and g, before neutralizing: \", cosine_similarity(word_to_vec_map[\"receptionist\"], g))\n",
    "\n",
    "e_debiased = neutralize(\"receptionist\", g, word_to_vec_map)\n",
    "print(\"cosine similarity between \" + e + \" and g, after neutralizing: \", cosine_similarity(e_debiased, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `-5.603740393746121e-17` 与答案不同但也足够小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(pair, bias_axis, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Debias gender specific words by following the equalize method described in the figure above.\n",
    "    \n",
    "    Arguments:\n",
    "    pair -- pair of strings of gender specific words to debias, e.g. (\"actress\", \"actor\") \n",
    "    bias_axis -- numpy-array of shape (50,), vector corresponding to the bias axis, e.g. gender\n",
    "    word_to_vec_map -- dictionary mapping words to their corresponding vectors\n",
    "    \n",
    "    Returns\n",
    "    e_1 -- word vector corresponding to the first word\n",
    "    e_2 -- word vector corresponding to the second word\n",
    "    \"\"\"\n",
    "    g = bias_axis\n",
    "\n",
    "    word1, word2 = pair\n",
    "    e_w1, e_w2 = word_to_vec_map[word1], word_to_vec_map[word2]\n",
    "    u = (e_w1 + e_w2) / 2\n",
    "    u_B = np.dot(u, g) / np.sum(np.square(g)) * g\n",
    "    u_orth = u - u_B\n",
    "    e_w1B = np.dot(e_w1, g) / np.sum(np.square(g)) * g\n",
    "    e_w2B = np.dot(e_w2, g) / np.sum(np.square(g)) * g\n",
    "    temp = np.sqrt(np.abs(1 - np.sum(np.square(u_orth))))\n",
    "    e_w1B_corrected = temp * (e_w1B - u_B) / np.linalg.norm((e_w1 - u_orth) - u_B)\n",
    "    e_w2B_corrected = temp * (e_w2B - u_B) / np.linalg.norm((e_w2 - u_orth) - u_B)\n",
    "    e_1 = e_w1B_corrected + u_orth\n",
    "    e_2 = e_w2B_corrected + u_orth\n",
    "\n",
    "    return e_1, e_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarities before equalizing:\n",
      "cosine_similarity(word_to_vec_map[\"man\"], gender) =  -0.11711095765336832\n",
      "cosine_similarity(word_to_vec_map[\"woman\"], gender) =  0.35666618846270376\n",
      "\n",
      "cosine similarities after equalizing:\n",
      "cosine_similarity(e1, gender) =  -0.7004364289309388\n",
      "cosine_similarity(e2, gender) =  0.7004364289309387\n"
     ]
    }
   ],
   "source": [
    "print(\"cosine similarities before equalizing:\")\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"man\\\"], gender) = \", cosine_similarity(word_to_vec_map[\"man\"], g))\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"woman\\\"], gender) = \", cosine_similarity(word_to_vec_map[\"woman\"], g))\n",
    "print()\n",
    "e1, e2 = equalize((\"man\", \"woman\"), g, word_to_vec_map)\n",
    "print(\"cosine similarities after equalizing:\")\n",
    "print(\"cosine_similarity(e1, gender) = \", cosine_similarity(e1, g))\n",
    "print(\"cosine_similarity(e2, gender) = \", cosine_similarity(e2, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
