{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')\n",
    "\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')\n",
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "\n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "\n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "\n",
    "    words = sentence.strip().lower().split(' ')\n",
    "    n_e = 50\n",
    "    avg = np.zeros((n_e, )) # a line vector instead of a col vector\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    avg /= len(words)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(132, 5)\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch: 0 --- cost = 1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = 0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = 0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = 0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \"\"\"\n",
    "    Model to train word vector representations in numpy.\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
    "    num_iterations -- number of iterations\n",
    "\n",
    "    Returns:\n",
    "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
    "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
    "    b -- bias of the softmax layer, of shape (n_y,)\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    n_y = 5\n",
    "    n_h = 50\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h) # WHY?\n",
    "    b = np.zeros((n_y,))\n",
    "    Y_oh = convert_to_one_hot(Y, C=n_y)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        for j in range(m):\n",
    "            avg = sentence_to_avg(X[j], word_to_vec_map)\n",
    "            y_pred = softmax(W @ avg + b)\n",
    "            y = Y_oh[j]\n",
    "\n",
    "            cost = -np.sum(y * np.log(y_pred))\n",
    "\n",
    "            dz = y_pred - y\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            W -= learning_rate * dW\n",
    "            b -= learning_rate * db\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: \" + str(i) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map)\n",
    "\n",
    "    return pred, W, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(132, 5)\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch: 0 --- cost = 1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = 0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = 0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = 0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n",
      "Epoch: 0 --- cost = 1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = 0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = 0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = 0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(X_train[0])\n",
    "print(type(X_train))\n",
    "Y = np.asarray([5,0,0,5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "\n",
    "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
    "'Lets go party and drinks','Congrats on the new job','Congratulations',\n",
    "'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
    "'You totally deserve this prize', 'Let us go play football',\n",
    "'Are you down for football this afternoon', 'Work hard play harder',\n",
    "'It is suprising how people can be dumb sometimes',\n",
    "'I am very disappointed','It is the best day in my life',\n",
    "'I think I will end up alone','My life is so boring','Good job',\n",
    "'Great so awesome'])\n",
    "\n",
    "print(X.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(type(X_train))\n",
    "\n",
    "# start training\n",
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "Test set:\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you ❤️\n",
      "i love you ❤️\n",
      "funny lol 😄\n",
      "lets play with a ball ⚾\n",
      "food is ready 🍴\n",
      "not feeling happy 😄\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           ❤️    ⚾    😄    😞   🍴\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    0    1    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            2    0   16    0    0   18\n",
      "3            1    1    2   12    0   16\n",
      "4            0    0    1    0    6    7\n",
      "All          9    9   19   13    6   56\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
